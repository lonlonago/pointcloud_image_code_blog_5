#  brief introduction 

 The algorithm in this paper won the championship in the CVPR 2019 Automated Driving Workshop 3D object detection challenge. The authors extract rich semantic features using sparse 3D convolution and feed them into a class-balanced multi-head network for 3D object detection. To solve the severe class imbalance problem that is naturally present in autonomous driving scenarios, the authors design a class-balanced sampling and enhancement strategy to generate a more balanced data distribution. In addition, the authors also propose a balanced grouping network header, which improves the classification performance of categories with similar shapes. The algorithm proposed in this paper significantly outperforms PointPillars on all evaluation metrics, achieving the detection performance of SOTA on the Scnuenes dataset. 

 Source Code: https://github.com/poodarchu/Det3D 

>  Figure 1: The distribution of instances of categories in the nuScenes dataset is long-tailed, showing an extreme imbalance in the number of examples of common and rare object categories. 

#  data augmentation 

##  DS_Sampling 

 Duplicate samples of a particular class based on the proportion of samples of a particular class in all samples. The fewer samples of a class, the more samples of that class are copied to form the final training dataset. To achieve a class-balanced dataset, all classes should have close proportions in the training split, specifically: 

 Overall, DS Sampling can be seen as increasing the average density of rare classes in the training split, which can effectively alleviate the imbalance problem, as shown in the orange column in Figure 1 

 Code reference: https://github.com/open-mmlab/OpenPCDet/blob/master/pcdet/datasets/nuscenes/nuscenes_dataset.py 

  ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 2024020309573797901
  ```  
 OpenPCDet code can be seen after balanced_infos_resampling, the number of each category is the same, and the above figure shows that the number of category instances before and after CBGS sampling does not change significantly 

##  GT-AUG 

 The ground truths are sampled from an offline generated annotation database using the GT-AUG strategy proposed in SECOND, and the sampled frames are placed in another point cloud. 

>  Before placing the object box correctly, the ground plane position of the point cloud sample needs to be calculated. The least squares method and RANSAC are used to estimate the ground plane of each sample 

>  Figure 2: Example of ground plane detection results, which can be expressed as Ax + By + Cz + D = 0. On average, the ground plane is about -1.82 meters along the z-axis. 

#  network architecture 

 The overall network architecture is shown in the figure below, including four parts: input module, 3D feature extraction, region proposal network, and multi-group header network. 

>  Figure 3: Network architecture. The 3D Feature Extractor consists of a submanifold and a regular 3D sparse convolution. The output of the 3D Feature Extractor is a 16-fold scaled-down, flattened along the output axis and fed into a subsequent regional proposal network to generate an 8-fold feature map, which is then generated by the multi-set header network for the final prediction. The number of header groups is set according to the grouping specification 

 Use sparse 3D convolution with jump connections to build a resnet-like architecture for the 3D feature extractor network. For the input tensor of one, the feature extractor outputs a feature map of one, m, n are the reduction factors of z, x, y dimensions respectively, and l is the last layer of the output channel 3D feature extractor. To make this 3D feature map more suitable for the Region Proposal Network and multi-set of headers below, reshape the feature map into, and then use, the region proposal network to perform regular 2D convolution and deconvolution to further aggregate features and obtain higher resolution feature maps. Based on these feature maps, multi-set of header networks are able to efficiently detect different classes of objects. 

##  class balanced grouping 

 An unbalanced data distribution can make the model dominate the majority of categories. As can be seen from Figure 2, the labeling of cars in the dataset accounts for 43.7%, which is 40 times that of bicycles. Therefore, if you train cars and bicycles together, and there is basically no bicycle data in a batch, the network will have a poor classification effect on bicycles. On the other hand, if you train samples of different shapes and sizes together, the regression targets will have greater intra-class differences, causing classes with different shapes to interfere with each other, which is why the network's performance when learning classes of different shapes at the same time is not as good as training separately. Intuitively, similar shapes have similar characteristics, and training together can promote each other... The two main principles are: 

 Manually divide all categories into groups according to some principles. For a specific header in a multi-group header module, it only needs to identify the class and locate the objects of the classes that belong to that group. There are mainly 2 principles guiding the effective division of 10 classes into groups: 

 Manually group 10 categories in the dataset into 6 groups based on certain principles: (Car), (Truck, Construction Vehicle), (Bus, Trailer), (Barrier), (Motorcycle, Bicycle), (Pedestrian, Traffic Cone). According to the ablation study, as shown in Table 4, class balance grouping contributed the most to the final result 

##  Loss function 

 The loss function part refers to SECOND. If the direction classification in SECOND is used, the mAOE will be very high. The direction of many predicted bounding boxes is exactly the opposite of the ground truth. Common problems such as the object forward and reverse problem (facing the opposite direction) are made in this part. Small improvements are made in this part. Additional direction classification targets are added to add offsets to eliminate direction ambiguity. As for speed estimation, regression without normalization can achieve the best performance compared to adding additional normalization operations. 

 In order to reduce the learning difficulty, the anchor mechanism is used, and other settings are similar to SECOND. Focal loss is used for Classification, Smoothl1 regression x, y, z, l, w, h, yaw, vx, vy, and it is worth mentioning that each branch uses Uniform Scaling as the learning weight. 

 In addition to the general classification and bounding box regression branches required for 3D object detection, we also add the directional classification branch proposed in SECOND [28]. It should be noted that according to our statistics, most of the object boxes are parallel or perpendicular to the LiDAR coordinate axis. Therefore, if directional classification is applied in SECOND, it turns out that the mAOE is very high because the direction of many predicted bounding boxes is exactly the opposite of the ground truth. Therefore, we add an offset to the directional classification target to eliminate directional ambiguity. As for velocity estimation, regression without normalization can achieve optimal performance compared to adding additional normalization operations. 

 In order to reduce the learning difficulty, the anchor mechanism is used. Referring to SECOND, different classes of anchors have different height and width configurations, determined by the class mean. A class has 1 size configuration and 2 different directions. For speed, the anchors are set to 0 on both the x and y axes, no need to estimate the speed on the z-axis. 

 In the experiment, multiple sets of headers were treated as a multi-task learning process, using Uniform Scaling to configure the weights of different branches 

#  Experimental results 

>  Table 2: Overall performance. BRAVE and Tolist are the other top three teams. Our approach achieved the best performance on all metrics except the mAAE metric 

>  Table 3: Comparison of mAP with PointPillars by category. Our method shows more competitive and balanced performance on the tail class. For example, Bicycle improved by 14 times. Motorcycles, construction vehicles (Cons. Veh.), trailers, traffic cones (TC) improved by more than 2 times 

>  Table 4: Ablation studies of the different components used in our validation split method. Database Sampling and Re-Encoder contributed the most to mAP 

>  Table 5: GT-AUG ratings for different categories. For each category, magnitude means the number of instances placed in the point cloud sample 

#  result 

 The performance of the proposed algorithm outperforms the baseline algorithm PointPillars by 73.1%, and for each class, especially for classes with fewer samples, the proposed algorithm has smaller errors in translation (mATE), scale (mASE), direction (mAOE), velocity (mAVE) and attributes (mAAE). 

>  Figure 4: Example of detection results in a validation split. Ground truth is annotated in green and detection results are in blue. Detection results are from a model with 51.9% mAP and 62.5% NDS. The markers at the top of each point cloud bird's-eye view image are their corresponding sample data markers. 

#  conclusion 

 One of the differences between the newly released autonomous driving dataset nuScence and kitti is that there are many categories, and the category samples are uneven. This article mainly proposes a new class imbalance solution. After augmenting the dataset, random sampling is used to balance fewer categories, and those with similar shapes are divided into groups. Categories with fewer samples can be improved by more categories with similar shapes 

